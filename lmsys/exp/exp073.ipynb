{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzT66iezisGu"
   },
   "source": [
    "# 目的\n",
    "psuedo labelingのデータを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:24.519355Z",
     "iopub.status.busy": "2024-07-30T15:22:24.519104Z",
     "iopub.status.idle": "2024-07-30T15:22:24.529508Z",
     "shell.execute_reply": "2024-07-30T15:22:24.528954Z"
    },
    "id": "v7YkHHYsisGw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e073-add-psuedo\"\n",
    "MODEL_NAME = \"unsloth/gemma-2-9b-it-bnb-4bit\"\n",
    "COMPETITION_NAME = \"lmsys\"\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = False\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = True\n",
    "UPLOAD_DATA_TO_KAGGLE = True\n",
    "REMOVE_LOCAL_FILE = False\n",
    "WANDB = True\n",
    "# USE_FOLD = 2\n",
    "USE_DATA_RATE = 1.0\n",
    "# VALID_DATA_SIZE = 3000\n",
    "\n",
    "# model parameter\n",
    "TRAINING_MAX_LENGTH = 2048 # 512\n",
    "# INFERENCE_MAX_LENGTH = 1536\n",
    "SEED = 42\n",
    "EPOCH = 1\n",
    "LR = 2e-04\n",
    "TRAIN_BS = 4 # 16\n",
    "GRAD_ACC_STEP= 128 // TRAIN_BS # 仮想的なバッチサイズはTRAIN_BS * GRAD_ACC_STEPとなる\n",
    "EVAL_BS = 4 # 16\n",
    "NUM_LABELS = 3\n",
    "\n",
    "FREEZE_LAYERS = (\n",
    "    0  # there're 42 layers in total, we don't add adapters to the first 16 layers\n",
    ")\n",
    "\n",
    "# rola parameter\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = LORA_R * 2\n",
    "LORA_DROPOUT = 0.05\n",
    "LORA_BIAS = \"none\"\n",
    "\n",
    "RESUME_FROM_CHECKPOINT= False # 途中から再開する場合はTrueにする\n",
    "# TRAINED_MODEL_PATH = \"lmsys/trained_models/e006-use-concat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:24.532385Z",
     "iopub.status.busy": "2024-07-30T15:22:24.531850Z",
     "iopub.status.idle": "2024-07-30T15:22:25.385515Z",
     "shell.execute_reply": "2024-07-30T15:22:25.384711Z"
    },
    "id": "k-1rTdTmisGy",
    "outputId": "325e68ee-4d23-4a14-ff44-df1acc833ad3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:25.388827Z",
     "iopub.status.busy": "2024-07-30T15:22:25.388558Z",
     "iopub.status.idle": "2024-07-30T15:22:25.812933Z",
     "shell.execute_reply": "2024-07-30T15:22:25.811893Z"
    },
    "id": "xdIcXQzqisGz",
    "outputId": "9de0ed12-bdfb-4fb2-c5b1-c6114afff122",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:25.816666Z",
     "iopub.status.busy": "2024-07-30T15:22:25.816116Z",
     "iopub.status.idle": "2024-07-30T15:22:25.822896Z",
     "shell.execute_reply": "2024-07-30T15:22:25.822280Z"
    },
    "id": "YeHMykyGisG0",
    "outputId": "7c447bf6-7758-40eb-aaee-4b35037d5567",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return \"kernel\", f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return \"nohup\", f\"../../{base_path}\"\n",
    "    elif cwd == f\"/content\":\n",
    "        print(\"Google Colab!\")\n",
    "        return \"colab\", f\"/content/drive/MyDrive/Kaggle/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd.startswith(\"/home/shinichiro.saito\"):\n",
    "        print(\"GCP!\")\n",
    "        return \"GCP\", f\"/home/shinichiro.saito/{COMPETITION_NAME}/{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "ENV_NAME, DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "_, MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:25.825757Z",
     "iopub.status.busy": "2024-07-30T15:22:25.825305Z",
     "iopub.status.idle": "2024-07-30T15:22:25.829439Z",
     "shell.execute_reply": "2024-07-30T15:22:25.828709Z"
    },
    "id": "E78wS3ypisG0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrbRPEvvisG0"
   },
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:25.832419Z",
     "iopub.status.busy": "2024-07-30T15:22:25.831858Z",
     "iopub.status.idle": "2024-07-30T15:22:25.850418Z",
     "shell.execute_reply": "2024-07-30T15:22:25.849587Z"
    },
    "id": "6KxXWNwhisG0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ENV_NAME != \"GCP\":\n",
    "    %pip install -qq polars==1.0.0\n",
    "    %pip install -qq transformers==4.42.3\n",
    "    %pip install -qq datasets==2.20.0\n",
    "    %pip install -qq evaluate==0.4.2\n",
    "    %pip install -qq seqeval==1.2.2\n",
    "    %pip install -qq accelerate==0.32.0\n",
    "    %pip install -qq python-dotenv==1.0.1\n",
    "    %pip install -qq wandb==0.17.4\n",
    "    %pip install -qq bitsandbytes==0.43.1\n",
    "    %pip install -qq accelerate==0.32.0\n",
    "    %pip install -qq peft==0.11.1\n",
    "\n",
    "    # formatter\n",
    "    %pip install -qq black isort\n",
    "\n",
    "    %pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3uVqXs-isG1"
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:25.853775Z",
     "iopub.status.busy": "2024-07-30T15:22:25.853171Z",
     "iopub.status.idle": "2024-07-30T15:22:30.589946Z",
     "shell.execute_reply": "2024-07-30T15:22:30.589214Z"
    },
    "id": "NPumFSeNisG1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, LayerNorm, MSELoss\n",
    "import wandb\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    Value,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    ClassLabel,\n",
    ")\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForSequenceClassification,\n",
    "    GemmaTokenizerFast,\n",
    "    Gemma2Config,\n",
    "    PreTrainedTokenizerBase,\n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:30.593672Z",
     "iopub.status.busy": "2024-07-30T15:22:30.592968Z",
     "iopub.status.idle": "2024-07-30T15:22:30.596669Z",
     "shell.execute_reply": "2024-07-30T15:22:30.595945Z"
    },
    "id": "fLkGFO2PisG1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "NUM_PROC = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:30.599503Z",
     "iopub.status.busy": "2024-07-30T15:22:30.599058Z",
     "iopub.status.idle": "2024-07-30T15:22:30.880988Z",
     "shell.execute_reply": "2024-07-30T15:22:30.879847Z"
    },
    "id": "7Ahs0mPMisG1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "import bitsandbytes\n",
    "import accelerate\n",
    "import peft\n",
    "\n",
    "assert transformers.__version__ == \"4.42.3\"\n",
    "assert datasets.__version__ == \"2.20.0\"\n",
    "assert evaluate.__version__ == \"0.4.2\"\n",
    "assert bitsandbytes.__version__ == \"0.43.1\"\n",
    "assert accelerate.__version__ == \"0.32.0\"\n",
    "assert peft.__version__ == \"0.11.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:30.885328Z",
     "iopub.status.busy": "2024-07-30T15:22:30.885003Z",
     "iopub.status.idle": "2024-07-30T15:22:30.891140Z",
     "shell.execute_reply": "2024-07-30T15:22:30.890452Z"
    },
    "id": "o3ZVc72wisG2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:30.894706Z",
     "iopub.status.busy": "2024-07-30T15:22:30.894108Z",
     "iopub.status.idle": "2024-07-30T15:22:30.905931Z",
     "shell.execute_reply": "2024-07-30T15:22:30.905320Z"
    },
    "id": "8-7WkHGUisG2",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "e8711fa2-cd7f-4291-e280-0915341f5efc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{DATA_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohXfhbqXisG2"
   },
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:30.945381Z",
     "iopub.status.busy": "2024-07-30T15:22:30.944970Z",
     "iopub.status.idle": "2024-07-30T15:22:42.374279Z",
     "shell.execute_reply": "2024-07-30T15:22:42.373445Z"
    },
    "id": "KGR9aE2YisG2",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "95031754-538e-4af9-efc0-dec4d85afaf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=COMPETITION_NAME, name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxyhkSG4isG2"
   },
   "source": [
    "# Data Import & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:42.377627Z",
     "iopub.status.busy": "2024-07-30T15:22:42.377349Z",
     "iopub.status.idle": "2024-07-30T15:22:42.380717Z",
     "shell.execute_reply": "2024-07-30T15:22:42.379976Z"
    },
    "id": "6X0GBaE-isG2"
   },
   "outputs": [],
   "source": [
    "# with open(f\"{DATA_PATH}/label_stratified_fold.json\") as f:\n",
    "#     label_stratified_fold = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:42.383678Z",
     "iopub.status.busy": "2024-07-30T15:22:42.383415Z",
     "iopub.status.idle": "2024-07-30T15:22:42.923832Z",
     "shell.execute_reply": "2024-07-30T15:22:42.922971Z"
    },
    "id": "JlTiKm6TisG2"
   },
   "outputs": [],
   "source": [
    "train = (\n",
    "    pl.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "    .with_columns(pl.col(\"id\").cast(pl.String))\n",
    "    # .with_columns(\n",
    "    #     pl.col(\"prompt\").str.json_decode(),\n",
    "    #     pl.col(\"response_a\").str.json_decode(),\n",
    "    #     pl.col(\"response_b\").str.json_decode(),\n",
    "    # )\n",
    "    # .with_columns(  # 長さの情報を追加する\n",
    "    #     pl.col(\"prompt\")\n",
    "    #     .map_elements(lambda x: len(x), return_dtype=pl.Int64)\n",
    "    #     .alias(\"len_prompt\"),\n",
    "    #     pl.col(\"response_a\")\n",
    "    #     .map_elements(lambda x: len(x), return_dtype=pl.Int64)\n",
    "    #     .alias(\"len_response_a\"),\n",
    "    #     pl.col(\"response_b\")\n",
    "    #     .map_elements(lambda x: len(x), return_dtype=pl.Int64)\n",
    "    #     .alias(\"len_response_b\"),\n",
    "    # )\n",
    "    # .with_columns(  # 最後のレスポンスのみを取得する\n",
    "    #     pl.col(\"prompt\")\n",
    "    #     .map_elements(lambda x: x[-1], return_dtype=pl.String)\n",
    "    #     .alias(\"last_prompt\"),\n",
    "    #     pl.col(\"response_a\")\n",
    "    #     .map_elements(lambda x: x[-1], return_dtype=pl.String)\n",
    "    #     .alias(\"last_response_a\"),\n",
    "    #     pl.col(\"response_b\")\n",
    "    #     .map_elements(lambda x: x[-1], return_dtype=pl.String)\n",
    "    #     .alias(\"last_response_b\"),\n",
    "    # )\n",
    "    # .with_columns(  # 最後のレスポンスがNoneの場合を空文字にする、約60件程度\n",
    "    #     pl.col(\"last_response_a\").fill_null(\"\"),\n",
    "    #     pl.col(\"last_response_b\").fill_null(\"\"),\n",
    "    # )\n",
    "    # .with_columns(  # labelを付与する\n",
    "    #     pl.when(pl.col(\"winner_model_a\") == 1)\n",
    "    #     .then(0)\n",
    "    #     .when(pl.col(\"winner_model_b\") == 1)\n",
    "    #     .then(1)\n",
    "    #     .when(pl.col(\"winner_tie\") == 1)\n",
    "    #     .then(2)\n",
    "    #     .alias(\"label\"),\n",
    "    # )\n",
    "    # .select(  # 元のprompt, responseを削除する\n",
    "    #     pl.exclude([\"prompt\", \"response_a\", \"response_b\"])\n",
    "    # )\n",
    "    # .with_columns(  # foldを追加する\n",
    "    #     pl.col(\"id\").replace(label_stratified_fold).alias(\"fold\")\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:42.927364Z",
     "iopub.status.busy": "2024-07-30T15:22:42.927064Z",
     "iopub.status.idle": "2024-07-30T15:22:43.076203Z",
     "shell.execute_reply": "2024-07-30T15:22:43.075461Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/takamichitoda/lmsys-convert-ultrafeedback-to-competition/output\n",
    "# extra_data = pl.read_csv(f\"{DATA_PATH}/ultrachat_s42_a0.5.csv\")\n",
    "\n",
    "# https://www.kaggle.com/datasets/abdullahmeda/lmsys-additional-33k-labelled-conversations?select=lmsys-33k-deduplicated.csv\n",
    "extra_data = pl.read_csv(f\"{DATA_PATH}/lmsys-33k-deduplicated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:43.079387Z",
     "iopub.status.busy": "2024-07-30T15:22:43.079087Z",
     "iopub.status.idle": "2024-07-30T15:22:43.431498Z",
     "shell.execute_reply": "2024-07-30T15:22:43.430745Z"
    }
   },
   "outputs": [],
   "source": [
    "psuedo_data_org = pl.read_csv(f\"{DATA_PATH}/ultrachat_s42_a0.5.csv\")\n",
    "psuedo_data_pred = pl.read_csv(f\"{DATA_PATH}/ultrafeedback_pred_27.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:43.434964Z",
     "iopub.status.busy": "2024-07-30T15:22:43.434427Z",
     "iopub.status.idle": "2024-07-30T15:22:43.443661Z",
     "shell.execute_reply": "2024-07-30T15:22:43.443006Z"
    }
   },
   "outputs": [],
   "source": [
    "psuedo_data = (\n",
    "    psuedo_data_org.select(\n",
    "        pl.exclude([\"winner_model_a\", \"winner_model_b\", \"winner_tie\"])\n",
    "    )\n",
    "    .join(\n",
    "        psuedo_data_pred,\n",
    "        on=\"id\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:43.446671Z",
     "iopub.status.busy": "2024-07-30T15:22:43.446128Z",
     "iopub.status.idle": "2024-07-30T15:22:43.966390Z",
     "shell.execute_reply": "2024-07-30T15:22:43.965629Z"
    }
   },
   "outputs": [],
   "source": [
    "def argmax_to_one(row):\n",
    "    max_index = row.to_list().index(max(row))\n",
    "    return [1 if i == max_index else 0 for i in range(len(row))]\n",
    "\n",
    "# Apply the function to each row\n",
    "psuedo_data = (\n",
    "    psuedo_data\n",
    "    .with_columns([\n",
    "        pl.concat_list([pl.col(c) for c in [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]])\n",
    "        .map_elements(argmax_to_one)\n",
    "        .alias(\"transformed\")\n",
    "        ]\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"transformed\").list.get(i).alias([\"winner_model_a\", \"winner_model_b\", \"winner_tie\"][i]) for i in range(3)\n",
    "    )\n",
    "    .drop(\"transformed\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:43.969935Z",
     "iopub.status.busy": "2024-07-30T15:22:43.969278Z",
     "iopub.status.idle": "2024-07-30T15:22:43.978166Z",
     "shell.execute_reply": "2024-07-30T15:22:43.977303Z"
    }
   },
   "outputs": [],
   "source": [
    "print(extra_data[\"winner_model_a\"].value_counts())\n",
    "print(extra_data[\"winner_model_b\"].value_counts())\n",
    "print(extra_data[\"winner_tie\"].value_counts())\n",
    "\n",
    "print(psuedo_data[\"winner_model_a\"].value_counts())\n",
    "print(psuedo_data[\"winner_model_b\"].value_counts())\n",
    "print(psuedo_data[\"winner_tie\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:43.981279Z",
     "iopub.status.busy": "2024-07-30T15:22:43.980677Z",
     "iopub.status.idle": "2024-07-30T15:22:43.984279Z",
     "shell.execute_reply": "2024-07-30T15:22:43.983691Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pl.concat([train, extra_data, psuedo_data], how=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:43.987088Z",
     "iopub.status.busy": "2024-07-30T15:22:43.986479Z",
     "iopub.status.idle": "2024-07-30T15:22:43.989751Z",
     "shell.execute_reply": "2024-07-30T15:22:43.989156Z"
    },
    "id": "6nkbuZVjisG3"
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.sample(fraction=1.0, shuffle=True).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:43.992458Z",
     "iopub.status.busy": "2024-07-30T15:22:43.991983Z",
     "iopub.status.idle": "2024-07-30T15:22:44.836182Z",
     "shell.execute_reply": "2024-07-30T15:22:44.835295Z"
    },
    "id": "FTg7of_kisG3"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_polars(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:44.839644Z",
     "iopub.status.busy": "2024-07-30T15:22:44.839125Z",
     "iopub.status.idle": "2024-07-30T15:22:44.843602Z",
     "shell.execute_reply": "2024-07-30T15:22:44.843000Z"
    },
    "id": "bd10PoSKisG3",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "7071529f-0e5d-4d82-facf-ccc179ce9150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "    num_rows: 112854\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:44.846558Z",
     "iopub.status.busy": "2024-07-30T15:22:44.845987Z",
     "iopub.status.idle": "2024-07-30T15:22:44.880657Z",
     "shell.execute_reply": "2024-07-30T15:22:44.880014Z"
    },
    "id": "RFYU2E04isG3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 計算を早くするために、データを減らす\n",
    "if not DEBUG:\n",
    "    train_dataset = train_dataset.shuffle().select(\n",
    "        range(\n",
    "            int(len(train_dataset) * USE_DATA_RATE)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHoxXNPjisG3"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:44.883722Z",
     "iopub.status.busy": "2024-07-30T15:22:44.883241Z",
     "iopub.status.idle": "2024-07-30T15:22:44.887407Z",
     "shell.execute_reply": "2024-07-30T15:22:44.886761Z"
    },
    "id": "Q280EkU0isG3"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA, # low-rankマトリクスのスケーリングファクター\n",
    "    # only target self-attention\n",
    "    # target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    target_modules=[ # Linear層を全て含める\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\"\n",
    "    ],\n",
    "    layers_to_transform=[i for i in range(42) if i >= FREEZE_LAYERS],\n",
    "    lora_dropout=LORA_DROPOUT, # LoRAレイヤーのドロップアウト確率\n",
    "    bias=LORA_BIAS,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:44.890109Z",
     "iopub.status.busy": "2024-07-30T15:22:44.889629Z",
     "iopub.status.idle": "2024-07-30T15:22:46.000043Z",
     "shell.execute_reply": "2024-07-30T15:22:45.999053Z"
    },
    "id": "elrKuvnhisG3",
    "outputId": "51724180-bb86-415d-bf3b-e549c6d776be"
   },
   "outputs": [],
   "source": [
    "# tokenizer = GemmaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
    "tokenizer.padding_side = \"right\"\n",
    "# tokenizer.add_special_tokens({\"additional_special_tokens\": [\"[SEP]\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:22:46.003979Z",
     "iopub.status.busy": "2024-07-30T15:22:46.003290Z",
     "iopub.status.idle": "2024-07-30T15:26:03.977605Z",
     "shell.execute_reply": "2024-07-30T15:26:03.976522Z"
    },
    "id": "jySgfPOTisG3",
    "outputId": "7369087b-3708-4d51-af6c-a4bf82f6c191"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=\"./model_cache\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "# model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "print(model)\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:26:03.980679Z",
     "iopub.status.busy": "2024-07-30T15:26:03.980071Z",
     "iopub.status.idle": "2024-07-30T15:26:03.983398Z",
     "shell.execute_reply": "2024-07-30T15:26:03.982794Z"
    },
    "id": "2-7dZwvZisG4"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO7YiwQeisG4"
   },
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:26:03.986219Z",
     "iopub.status.busy": "2024-07-30T15:26:03.985644Z",
     "iopub.status.idle": "2024-07-30T15:26:03.993654Z",
     "shell.execute_reply": "2024-07-30T15:26:03.993069Z"
    },
    "id": "MQT3oLTVisG4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cut_most_length_text(prompt: str, response_a: str, response_b: str, cut_num: int):\n",
    "\n",
    "    prompt_len = len(prompt.split(\" \"))\n",
    "    response_a_len = len(response_a.split(\" \"))\n",
    "    response_b_len = len(response_b.split(\" \"))\n",
    "    \n",
    "    if (prompt_len >= response_a_len) & (prompt_len >= response_b_len):\n",
    "        prompt = \" \".join(prompt.split(\" \")[:-cut_num])\n",
    "    elif (response_a_len >= prompt_len) & (response_a_len >= response_b_len):\n",
    "        response_a = \" \".join(response_a.split(\" \")[:-cut_num])\n",
    "    elif (response_b_len >= prompt_len) & (response_b_len >= response_a_len):\n",
    "        response_b = \" \".join(response_b.split(\" \")[:-cut_num])\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    return prompt, response_a, response_b\n",
    "\n",
    "def tokenize(example):\n",
    "    cut_len = TRAINING_MAX_LENGTH - 16 # bos, '\\n\\n', '<', 'prompt', '>:',  '<', 'response', '_', 'a', '>:', '<',  'response',  '_',  'b',  '>:', eos\n",
    "    \n",
    "    # 要素が　null　の場合を\"\"に置換する\n",
    "    # listにする\n",
    "    prompt = \" \".join(eval(example[\"prompt\"], {\"null\": \"\"}))\n",
    "    response_a = \" \".join(eval(example[\"response_a\"], {\"null\": \"\"}))\n",
    "    response_b = \" \".join(eval(example[\"response_b\"], {\"null\": \"\"}))\n",
    "    \n",
    "    prompt = \"<prompt>: \" + prompt\n",
    "    response_a = \"\\n\\n<response_a>: \" + response_a\n",
    "    response_b = \"\\n\\n<response_b>: \" + response_b\n",
    "    \n",
    "    texts = prompt + response_a + response_b\n",
    "    \n",
    "    # 収まるまで、最も長いテキストを1単語ずつ減らす\n",
    "    # 遅い、5000件で1分ぐらいかかる\n",
    "    while len(texts.split(\" \")) > cut_len:\n",
    "        prompt, response_a, response_b = cut_most_length_text(prompt, response_a, response_b, 1)\n",
    "        texts = prompt + response_a + response_b\n",
    "    \n",
    "    tokenized = tokenizer(texts, max_length=TRAINING_MAX_LENGTH, truncation=True)\n",
    "    \n",
    "    if example[\"winner_model_a\"]:\n",
    "        label = 0\n",
    "    elif example[\"winner_model_b\"]:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "        \n",
    "    return {**tokenized, \"labels\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "cc24c5012cab4e769356a765797cab3c",
      "791e0fadf8e84fd8aeb655b2af357ebf",
      "69a0f43a549248a5a894f5e4efc03399",
      "6fd4cf8624aa4a4c94e7fe039b32a5d4",
      "2bd891a379f44467ad15354dae336aea",
      "9fdf70d5dd57401f994d49bb7eedd816",
      "ccf5e3386d1c4a67af2204a489ba949f",
      "bda4aae101554711aa35ab854494fa0f",
      "7bbe1ba1070e4fa98cda5cc78327a4ec",
      "79f3efdebd564ec08e4c8708dccd0888",
      "d88d28b6b84a41179b10b804865e4c78"
     ]
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:26:03.996345Z",
     "iopub.status.busy": "2024-07-30T15:26:03.995770Z",
     "iopub.status.idle": "2024-07-30T15:38:39.404878Z",
     "shell.execute_reply": "2024-07-30T15:38:39.404169Z"
    },
    "id": "NshkFfjWisG4",
    "outputId": "0ca656ea-6f40-40fd-d5f7-5e6c81ad2a76",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586b8067499c4878867b50deed65c9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/112854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:38:39.408086Z",
     "iopub.status.busy": "2024-07-30T15:38:39.407461Z",
     "iopub.status.idle": "2024-07-30T15:38:39.412125Z",
     "shell.execute_reply": "2024-07-30T15:38:39.411269Z"
    },
    "id": "l_EG6sLQisG4",
    "outputId": "c67f3253-afae-48dd-e3fe-6abe42d29bae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto",
    "execution": {
     "iopub.execute_input": "2024-07-30T15:38:39.414847Z",
     "iopub.status.busy": "2024-07-30T15:38:39.414206Z",
     "iopub.status.idle": "2024-07-30T15:38:39.417602Z",
     "shell.execute_reply": "2024-07-30T15:38:39.417024Z"
    },
    "id": "gxZYjUbgisG5",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def tokenize(examples, max_token_length: int):\n",
    "#     separator = \" [SEP] \"\n",
    "\n",
    "#     joined_text = (\n",
    "#         examples[\"last_prompt\"]\n",
    "#         + separator\n",
    "#         + examples[\"last_response_a\"]\n",
    "#         + separator\n",
    "#         + examples[\"last_response_b\"]\n",
    "#     )\n",
    "\n",
    "#     return tokenizer(\n",
    "#         joined_text,\n",
    "#         max_length=max_token_length,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.map(\n",
    "#     tokenize,\n",
    "#     batched=False,\n",
    "#     fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "#     num_proc=NUM_PROC,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb_WWMPkisG5"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211,
     "referenced_widgets": [
      "eaf162bcbea14891b9c7be1d71939cbb",
      "744ed7af03c14b218efbc64b8e3124b0",
      "d61c45c9d9bc40a3a57bbccce7915a89",
      "973f06f63e7c47b5975d320eae6a9628",
      "cda79eaa72fd48bb977bed6e4a3e07c0",
      "25caaed5c1234abeb5050f83e7c6a7f0",
      "21f80d5bd8724f0c9886744a8f53c34f",
      "d6a95ffa362b404fa693c4cd1f9b3c63",
      "df49af5f44b94c82b0fca742371ef11c",
      "647bf14b55824aaa91e7f813ca64b809",
      "f6bad0b2326346c687d5f1e6352d0db9",
      "51101312df764e49bc113cf6e403452c",
      "7183eb79f98c49bbac58bc1f8dbbaebb",
      "18bb312988a34a819da9adde886c927f",
      "490828abaf884396956815e8bd967403",
      "9f51c4ce2a654241898900dbc2d6e252",
      "5d0d582fecba431894224a2940d07dc0",
      "8dda8d9fce774c1399d8dc3e449aec25",
      "246a8b5b5ad046239b0cde3ea8ccb12c",
      "5fcb3a5ed3864e2ba62c46f5cb68de49",
      "0e37595bad814e42b7140303d876f80a",
      "821935c8bf1c4b8fb71f4b1816fccc69"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-07-30T15:38:39.420299Z",
     "iopub.status.busy": "2024-07-30T15:38:39.419753Z",
     "iopub.status.idle": "2024-07-30T15:38:39.422811Z",
     "shell.execute_reply": "2024-07-30T15:38:39.422205Z"
    },
    "id": "f86H6hZGisG5",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "cc20f623-e6d1-4ba8-83ea-c471699ca29e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filtered_train = train_dataset.filter(lambda x: x[\"fold\"] != USE_FOLD, num_proc=NUM_PROC)\n",
    "# filtered_valid = train_dataset.filter(lambda x: x[\"fold\"] == USE_FOLD, num_proc=NUM_PROC)\n",
    "# filtered_valid = filtered_valid.select(range(min(VALID_DATA_SIZE, len(filtered_valid))))\n",
    "\n",
    "# train_valid_dataset = DatasetDict(\n",
    "#     {\n",
    "#         \"train\": filtered_train,\n",
    "#         \"valid\": filtered_valid,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# del filtered_train, filtered_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:38:39.425419Z",
     "iopub.status.busy": "2024-07-30T15:38:39.424826Z",
     "iopub.status.idle": "2024-07-30T15:38:39.428637Z",
     "shell.execute_reply": "2024-07-30T15:38:39.428073Z"
    },
    "id": "BKqwVX_risG5",
    "outputId": "93c91d65-70c9-4a2a-b29e-099916001565",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:38:39.431175Z",
     "iopub.status.busy": "2024-07-30T15:38:39.430761Z",
     "iopub.status.idle": "2024-07-30T15:38:39.434596Z",
     "shell.execute_reply": "2024-07-30T15:38:39.434015Z"
    },
    "id": "DyY1QXduisG5"
   },
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     preds_prob = softmax(predictions, axis=-1)\n",
    "#     return {\"log_loss\": log_loss(labels, preds_prob)}\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred) -> dict:\n",
    "    preds, labels = eval_pred\n",
    "    preds_prob = softmax(preds, axis=-1)\n",
    "    return {\n",
    "        \"log_loss\": log_loss(y_true=labels, y_pred=preds_prob),\n",
    "        \"acc\": accuracy_score(y_true=labels, y_pred=preds.argmax(-1)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T15:38:39.437062Z",
     "iopub.status.busy": "2024-07-30T15:38:39.436610Z",
     "iopub.status.idle": "2024-07-30T15:38:39.471006Z",
     "shell.execute_reply": "2024-07-30T15:38:39.470286Z"
    },
    "id": "UfmFFtf0isG5"
   },
   "outputs": [],
   "source": [
    "# スケジューラの設定\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_STEP,\n",
    "    eval_accumulation_steps=GRAD_ACC_STEP,\n",
    "    # per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    do_eval=False,\n",
    "    # eval_strategy=\"steps\",\n",
    "    eval_strategy=\"no\",\n",
    "    # eval_steps=0.1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=0.1,\n",
    "    save_total_limit=10,\n",
    "    logging_steps=2,\n",
    "    seed=SEED,\n",
    "    # metric_for_best_model=\"eval_loss\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\", # \"linear\", # \"constant_with_warmup\",\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    # load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    # fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_8bit\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    # train_dataset=train_valid_dataset[\"train\"],\n",
    "    train_dataset=train_dataset,\n",
    "    # train_dataset=ConcatDataset(train_valid_dataset[\"train\"]),\n",
    "    # eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    # eval_dataset=ConcatDataset(train_valid_dataset[\"valid\"]),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-30T15:38:39.474126Z",
     "iopub.status.busy": "2024-07-30T15:38:39.473592Z",
     "iopub.status.idle": "2024-08-01T02:03:47.372453Z",
     "shell.execute_reply": "2024-08-01T02:03:47.371718Z"
    },
    "id": "SBF60C8tisG5",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "253fa451-bedd-43cd-e60b-029896920310"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='881' max='881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [881/881 34:22:06, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.672700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.842900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.599500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.280600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.162700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.135800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.077300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.942900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.905500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.990100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.979200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.920600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.896800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.915600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.893200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.959700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.898500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.876600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.979100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.932600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.849400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.885900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.820700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.917300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.929700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.866800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.881200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.905600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.868200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.916200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.887200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.850700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.778900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.791400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.856800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.808300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.828300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.865200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.868400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.881100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.865400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.839100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.893200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.928600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.870800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.833900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.845300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.937700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.829300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.849200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.855800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.766100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.834500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.894900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.892900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.891700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.988200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.952700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>1.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.918600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.922100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>1.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.828200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.915600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.802800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.765500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.843600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.937400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.876400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.988200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.829600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.889100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.803400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.820300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.817400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.767800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.935400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.764100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.806400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.888500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.798900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.827800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.848700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>0.832300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>0.793100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.859400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.777100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.906400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.928300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>0.904500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>0.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>0.804100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>0.924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>0.800300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>0.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.828800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>0.899300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.839200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.800200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>0.897200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>0.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>0.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.782200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>0.718700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>0.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>0.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.870400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>0.920700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.836900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>0.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.795900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>0.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>0.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>0.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>0.897400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.921300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.900400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>0.820200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>0.752600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>0.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.748600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0.762400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.823900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>0.896900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>0.808800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>0.792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>0.796900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.861800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>0.871400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>0.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>0.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>0.736600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.697400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>0.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>0.735500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>0.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.753600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>0.856000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>0.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.741400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>0.833800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.793900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.864600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>0.896300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>0.830600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>0.781400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.811700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>0.727200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>0.751400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>0.791400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>0.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>0.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>0.748100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>0.770500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>0.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>0.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>0.811300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.742400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.756800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.832200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.881200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>0.836300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>508</td>\n",
       "      <td>0.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.839200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.806500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514</td>\n",
       "      <td>0.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>0.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>0.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>0.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>0.819800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526</td>\n",
       "      <td>0.879600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>0.673900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.851400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>0.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>0.719300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>0.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538</td>\n",
       "      <td>0.706500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.733700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542</td>\n",
       "      <td>0.849400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>0.876800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>0.848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0.745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556</td>\n",
       "      <td>0.797400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558</td>\n",
       "      <td>0.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.789900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>0.776300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>0.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>0.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>0.764700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.769700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>0.727800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574</td>\n",
       "      <td>0.782400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>0.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>0.745900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>0.815500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>0.856000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.796300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592</td>\n",
       "      <td>0.740200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>0.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596</td>\n",
       "      <td>0.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598</td>\n",
       "      <td>0.793500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602</td>\n",
       "      <td>0.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>0.831100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>0.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608</td>\n",
       "      <td>0.815700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.754400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>0.850600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>614</td>\n",
       "      <td>0.694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616</td>\n",
       "      <td>0.800700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618</td>\n",
       "      <td>0.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.794900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>0.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>0.678100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626</td>\n",
       "      <td>0.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>628</td>\n",
       "      <td>0.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>632</td>\n",
       "      <td>0.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>634</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636</td>\n",
       "      <td>0.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>0.692500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.774300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>0.812300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>644</td>\n",
       "      <td>0.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>646</td>\n",
       "      <td>0.737100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>0.775800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.770400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>652</td>\n",
       "      <td>0.742400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>0.803300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>656</td>\n",
       "      <td>0.771100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>658</td>\n",
       "      <td>0.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.813800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.806300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>0.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>0.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>668</td>\n",
       "      <td>0.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.844300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>0.751300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>0.728900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>0.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678</td>\n",
       "      <td>0.708200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>0.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>684</td>\n",
       "      <td>0.787200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>0.703200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>688</td>\n",
       "      <td>0.780300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>692</td>\n",
       "      <td>0.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694</td>\n",
       "      <td>0.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>0.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>0.782400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.724400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>0.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>0.700900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>0.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>0.644700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>0.780800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>716</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>718</td>\n",
       "      <td>0.803300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>724</td>\n",
       "      <td>0.783200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>0.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>0.734700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>732</td>\n",
       "      <td>0.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>734</td>\n",
       "      <td>0.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>0.699600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>0.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.773800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>742</td>\n",
       "      <td>0.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>746</td>\n",
       "      <td>0.619400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>0.793700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>0.774500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>754</td>\n",
       "      <td>0.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>758</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>762</td>\n",
       "      <td>0.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>0.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>0.769700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>772</td>\n",
       "      <td>0.750500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>774</td>\n",
       "      <td>0.658100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>776</td>\n",
       "      <td>0.746600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778</td>\n",
       "      <td>0.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.749300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>0.782400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784</td>\n",
       "      <td>0.810200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>786</td>\n",
       "      <td>0.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>788</td>\n",
       "      <td>0.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>0.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>794</td>\n",
       "      <td>0.650600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>0.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>0.822200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>802</td>\n",
       "      <td>0.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>804</td>\n",
       "      <td>0.661800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>806</td>\n",
       "      <td>0.747400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>0.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>812</td>\n",
       "      <td>0.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>0.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>816</td>\n",
       "      <td>0.682800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>0.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.758700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>0.733300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824</td>\n",
       "      <td>0.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>0.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>828</td>\n",
       "      <td>0.747200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.715900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>0.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>834</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>0.764200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>838</td>\n",
       "      <td>0.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>842</td>\n",
       "      <td>0.765200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>844</td>\n",
       "      <td>0.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>0.697600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>0.749700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852</td>\n",
       "      <td>0.741500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>854</td>\n",
       "      <td>0.824600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>0.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>0.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>0.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>0.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>866</td>\n",
       "      <td>0.684100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>0.803900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.699500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>872</td>\n",
       "      <td>0.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>874</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>0.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>0.675900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    # モデルの学習\n",
    "    trainer.train(\n",
    "        resume_from_checkpoint = RESUME_FROM_CHECKPOINT if RESUME_FROM_CHECKPOINT else None\n",
    "    )\n",
    "    # ログの保存に利用したストレージを削除\n",
    "    # os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "    # モデルの保存\n",
    "    trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "else:\n",
    "    # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        TRAINED_MODEL_PATH,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )\n",
    "    # model = CustomDebertaSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        \".\",\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDb8ehD7isG6"
   },
   "source": [
    "```\n",
    "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
    "TODO: この　Warningが問題ないのかを調べる\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6kx7STcisG6"
   },
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "0fa1f69466ec4d129294ec4f3701fd55",
      "178d8c3896b04179bd91c1d7fac2ea78",
      "3ad230d273da46549f0f06f5253adc98",
      "01028bf39e0349c293a5463e0e376409",
      "92add8d0d2454c5180d50388c075c9a6",
      "9ab77d545cf7487d84b249266ff63110",
      "86daf780bd464e84bf4aa0ac7aa1dfe5",
      "0280bf7931b54ff0934af8f61087123c",
      "0ab33826eba2415296496c5588f61e8b",
      "d76816865dff49d390841242f29a4533",
      "287fa326e7664d90afa7b1646f47bd80",
      "d3990d443f864e6d9e08c3740ad3365d",
      "d0f59de9b0e74ff7b9a6eeedc1558297",
      "035e839b47944625850c72909e3956e4",
      "5cca871d48c2409a98ba569fd38657d1",
      "17fb584af537469c82dc35f5a6be4d75",
      "042b719e1a10411da5cf03936df56a05",
      "32c4997e532a4c14b23acebb6a1108e5",
      "aef72278c29f4bfcb300fe7828db4b6d",
      "b56cf491716b45b1a1bc73a533ae56d8",
      "9ba82afbe5994af58cd1e42859a21a0e",
      "4013ccd327794b80b18a022503871875",
      "d60205bbd0b64e79b2ac5bdbb2539de2",
      "a2fe626a7a0b4ef2890a475ab871b413",
      "d62949248fcb45c3bdcd2edaa933e2af",
      "b6ce65d7e39b4410b6d648b86b742a28",
      "4ce4a667c5d14cc4bbc7773290e78021",
      "ad0bb68a59ff49e0a944f926d1116dd3",
      "defdc74ea1944ec9a0bd924c529eae36",
      "0b3481011b484e578b8895ae7806d6d3",
      "75c48da7f73a4e689ece672f3c7a4ae0",
      "ee0c5fe624464489875a372ef6d93699",
      "f6fc1b1011a1417ba6f72566ea13528a",
      "e076ee58bdae4f4daddd71b360c2771e",
      "2f20f1a8606c4848ae765eca37cf5f4a",
      "5352b531641e441eb6f6ad985facddde",
      "d1361c9865ae42ee80adcf79f906ccfe",
      "a57ec2c7e64646cfbcf1f4474205ea83",
      "3b9f31e6b4c74fbb8195b3a99ca3dc42",
      "fe3e5682960f40f8992d311135342b17",
      "fb144b8ee9a343bdbee3678141f209b8",
      "0cf25349ef9d4a6d89e91244baf4873a",
      "381314cb86da43058322247f99c18842",
      "5aa5ade506c24318a4cd599eb879be25"
     ]
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-01T02:03:47.376412Z",
     "iopub.status.busy": "2024-08-01T02:03:47.375606Z",
     "iopub.status.idle": "2024-08-01T02:03:47.379944Z",
     "shell.execute_reply": "2024-08-01T02:03:47.379350Z"
    },
    "id": "oSbl-eNpisG6",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "648693b8-d416-4cad-83f3-20ffb840037f"
   },
   "outputs": [],
   "source": [
    "# # TRAININGをINFERRENCEでMAX_TOKENを変えるために、validを作り直す\n",
    "# valid_dataset = train_dataset.filter(\n",
    "#     lambda example: example[\"id\"] in train_valid_dataset[\"valid\"][\"id\"],\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     CustomTokenizer(tokenizer, max_length=INFERENCE_MAX_LENGTH),\n",
    "#     batched=True,\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "# # valid_dataset = valid_dataset.map(\n",
    "# #     tokenize,\n",
    "# #     batched=False,\n",
    "# #     fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "# #     num_proc=NUM_PROC,\n",
    "# # )\n",
    "\n",
    "# # valid_dataset = valid_dataset.map(\n",
    "# #     tokenize,\n",
    "# #     batched=False,\n",
    "# #     fn_kwargs={\n",
    "# #         \"suffix\": \"a\",\n",
    "# #         \"max_token_length\": INFERENCE_MAX_LENGTH\n",
    "# #     },\n",
    "# #     num_proc=NUM_PROC,\n",
    "# # ).map(\n",
    "# #     tokenize,\n",
    "# #     batched=False,\n",
    "# #     fn_kwargs={\n",
    "# #         \"suffix\": \"b\",\n",
    "# #         \"max_token_length\": INFERENCE_MAX_LENGTH\n",
    "# #     },\n",
    "# #     num_proc=NUM_PROC,\n",
    "# # )\n",
    "\n",
    "\n",
    "# def add_valid_pred(example, idx, valid_pred):\n",
    "#     example[\"valid_pred\"] = valid_pred[idx]\n",
    "#     return example\n",
    "\n",
    "\n",
    "# valid_dataset = train_valid_dataset[\"valid\"]\n",
    "\n",
    "# valid_pred = softmax(trainer.predict(valid_dataset).predictions, axis=-1)\n",
    "# # valid_pred = softmax(trainer.predict(ConcatDataset(valid_dataset)).predictions, axis=-1)\n",
    "\n",
    "# np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    "# )\n",
    "\n",
    "# valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDOqk7xeisG6"
   },
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-01T02:03:47.382362Z",
     "iopub.status.busy": "2024-08-01T02:03:47.382110Z",
     "iopub.status.idle": "2024-08-01T02:03:47.384858Z",
     "shell.execute_reply": "2024-08-01T02:03:47.384291Z"
    },
    "id": "yFU5fHWw8es_",
    "outputId": "520ecf60-cd58-4259-bfd5-95fdd6d5a95f"
   },
   "outputs": [],
   "source": [
    "# cv_score = log_loss(valid_dataset[\"labels\"], valid_pred)\n",
    "# print(f\"CV Score: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T02:03:47.387293Z",
     "iopub.status.busy": "2024-08-01T02:03:47.386876Z",
     "iopub.status.idle": "2024-08-01T02:03:47.389595Z",
     "shell.execute_reply": "2024-08-01T02:03:47.389030Z"
    },
    "id": "exp87mDcisG7"
   },
   "outputs": [],
   "source": [
    "# # output_textを保存\n",
    "# with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "#     f.write(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt4jBGyxisG7"
   },
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-01T02:03:47.392078Z",
     "iopub.status.busy": "2024-08-01T02:03:47.391846Z",
     "iopub.status.idle": "2024-08-01T02:04:40.544113Z",
     "shell.execute_reply": "2024-08-01T02:04:40.542942Z"
    },
    "id": "lupk0lEqisG7",
    "outputId": "c9a3fd96-b5c2-4c0c-8fe6-974459216930",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3へのアップロード\n",
    "# TODO: colabでは動かないため直す\n",
    "if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://{COMPETITION_NAME}/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T02:04:40.548287Z",
     "iopub.status.busy": "2024-08-01T02:04:40.547557Z",
     "iopub.status.idle": "2024-08-01T02:04:40.552014Z",
     "shell.execute_reply": "2024-08-01T02:04:40.551390Z"
    },
    "id": "oA3GNoNAisG7"
   },
   "outputs": [],
   "source": [
    "# ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e005-regression /notebooks/automated_essay_scoring/trained_models/e005-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XyyX1JqisG7"
   },
   "source": [
    "# Kaggle Datasetへのupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-01T02:04:40.554716Z",
     "iopub.status.busy": "2024-08-01T02:04:40.554248Z",
     "iopub.status.idle": "2024-08-01T02:04:40.566465Z",
     "shell.execute_reply": "2024-08-01T02:04:40.565791Z"
    },
    "id": "2yljmioJisG7",
    "outputId": "5eb1319b-0b11-4317-f01b-cf227b3232c2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(f\"cp /{DATA_PATH}/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-01T02:04:40.569470Z",
     "iopub.status.busy": "2024-08-01T02:04:40.568872Z",
     "iopub.status.idle": "2024-08-01T02:05:25.885893Z",
     "shell.execute_reply": "2024-08-01T02:05:25.885164Z"
    },
    "id": "EBXdM74XisG7",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "290aef28-6839-4562-bca9-53f774396d12",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not DEBUG and UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6KFg2LNisG8"
   },
   "source": [
    "# ローカルからのデータの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T02:05:25.889040Z",
     "iopub.status.busy": "2024-08-01T02:05:25.888492Z",
     "iopub.status.idle": "2024-08-01T02:05:25.891679Z",
     "shell.execute_reply": "2024-08-01T02:05:25.891077Z"
    },
    "id": "tFhHkzi3isG8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if not DEBUG and REMOVE_LOCAL_FILE:\n",
    "#     # ローカルからは削除\n",
    "#     os.system(f\"rm -rf {MODEL_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ae1f8a8d15114a55a81d98bbc4563ffa",
      "24846464fd9949488c69b7c8262b8176",
      "a6025d29e90449f49116bb74afc3b591",
      "fc246d5347ee4fc782a9f42e1fb38ffe",
      "e0a0206188b34cb0bbbb62921d4edfb4",
      "b3b2143d95a04a8ab99d72d3ede6012a",
      "13c10dcfeeef4c1a882f260bf1628be2",
      "83014dfe9f554182ab1933951c39f693"
     ]
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-01T02:05:25.894467Z",
     "iopub.status.busy": "2024-08-01T02:05:25.893935Z",
     "iopub.status.idle": "2024-08-01T02:05:31.215874Z",
     "shell.execute_reply": "2024-08-01T02:05:31.215232Z"
    },
    "id": "bL2CHIBOisG8",
    "outputId": "5b5cbe19-9070-4319-8867-637c31771b00",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": "auto",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-01T02:05:31.218941Z",
     "iopub.status.busy": "2024-08-01T02:05:31.218401Z",
     "iopub.status.idle": "2024-08-01T02:05:31.222293Z",
     "shell.execute_reply": "2024-08-01T02:05:31.221692Z"
    },
    "id": "ohN9BBugisG8",
    "outputId": "28bd693d-d1fe-4c50-d81b-3412267d48a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mH-uPM5EuoqS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3ef95714d1064b53a58447b5cd3b85de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "50db5f22087f4a0db0de17dc5f0ae360": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8af69f64b5e74977a28aaf7e1f8f8c35",
       "placeholder": "​",
       "style": "IPY_MODEL_dc58809f44894a86b9db3c31e0bb93b8",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "558bcc5b0e39479bac96822aec4d7d38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_88a34e19568e485a8b30d02a2bead2bd",
       "placeholder": "​",
       "style": "IPY_MODEL_3ef95714d1064b53a58447b5cd3b85de",
       "tabbable": null,
       "tooltip": null,
       "value": " 112854/112854 [12:35&lt;00:00, 223.15 examples/s]"
      }
     },
     "586b8067499c4878867b50deed65c9ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_50db5f22087f4a0db0de17dc5f0ae360",
        "IPY_MODEL_fee209a2503d47b09477ab8be81ea602",
        "IPY_MODEL_558bcc5b0e39479bac96822aec4d7d38"
       ],
       "layout": "IPY_MODEL_f25497fb42794b2bbf3bad4ae95a7de0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "88a34e19568e485a8b30d02a2bead2bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8af69f64b5e74977a28aaf7e1f8f8c35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b745e912e064c29bdb3aac73a813c35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b6ffd762febf4491ac7a8c4077ffa910": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc58809f44894a86b9db3c31e0bb93b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f25497fb42794b2bbf3bad4ae95a7de0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fee209a2503d47b09477ab8be81ea602": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b6ffd762febf4491ac7a8c4077ffa910",
       "max": 112854.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9b745e912e064c29bdb3aac73a813c35",
       "tabbable": null,
       "tooltip": null,
       "value": 112854.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
