{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "Concatを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e006-use-concat\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-xsmall\"\n",
    "COMPETITION_NAME = \"lmsys\"\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = True\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = True\n",
    "UPLOAD_DATA_TO_KAGGLE = True\n",
    "WANDB = True\n",
    "\n",
    "# model parameter\n",
    "TRAINING_MAX_LENGTH = 1024\n",
    "INFERENCE_MAX_LENGTH = 1536\n",
    "SEED = 42\n",
    "VALID_DATA_SIZE = 0.3\n",
    "EPOCH = 3\n",
    "LR = 2e-05\n",
    "TRAIN_BS = 4\n",
    "GRAD_ACC_NUM = 16\n",
    "EVAL_BS = 4\n",
    "NUM_LABELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  8 23:40:10 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 61%   84C    P2   285W / 300W |   3293MiB / 49140MiB |     92%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/lmsys/lmsys/exp\n",
      "Jupyter Lab!\n",
      "../../data\n",
      "/notebooks/lmsys/lmsys/exp\n",
      "Jupyter Lab!\n",
      "../../trained_models/e006-use-concat\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq polars==1.0.0\n",
    "%pip install -qq transformers==4.42.3\n",
    "%pip install -qq datasets==2.20.0\n",
    "%pip install -qq evaluate==0.4.2\n",
    "%pip install -qq seqeval==1.2.2\n",
    "%pip install -qq accelerate==0.32.0\n",
    "%pip install -qq python-dotenv==1.0.1\n",
    "%pip install -qq wandb==0.17.4\n",
    "\n",
    "# formatter\n",
    "%pip install -qq black isort\n",
    "\n",
    "%pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 23:40:48.800132: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 23:40:48.800194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 23:40:48.801145: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 23:40:48.807128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 23:40:49.713855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from datasets import Dataset, DatasetDict, Value, concatenate_datasets, load_dataset, ClassLabel\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "NUM_PROC = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "assert transformers.__version__ == \"4.42.3\"\n",
    "assert datasets.__version__ == \"2.20.0\"\n",
    "assert evaluate.__version__ == \"0.4.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{DATA_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/lmsys/lmsys/exp/wandb/run-20240708_234106-48hrxund</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sinchir0/lmsys/runs/48hrxund' target=\"_blank\">e006-use-concat</a></strong> to <a href='https://wandb.ai/sinchir0/lmsys' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sinchir0/lmsys' target=\"_blank\">https://wandb.ai/sinchir0/lmsys</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sinchir0/lmsys/runs/48hrxund' target=\"_blank\">https://wandb.ai/sinchir0/lmsys/runs/48hrxund</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=COMPETITION_NAME, name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (\n",
    "    pl.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "    .with_columns(\n",
    "        pl.col(\"prompt\").str.json_decode(),\n",
    "        pl.col(\"response_a\").str.json_decode(),\n",
    "        pl.col(\"response_b\").str.json_decode(),\n",
    "    )\n",
    "    .with_columns( # 長さの情報を追加する\n",
    "        pl.col(\"prompt\").map_elements(lambda x: len(x), return_dtype=pl.Int64).alias(\"len_prompt\"),\n",
    "        pl.col(\"response_a\").map_elements(lambda x: len(x), return_dtype=pl.Int64).alias(\"len_response_a\"),\n",
    "        pl.col(\"response_b\").map_elements(lambda x: len(x), return_dtype=pl.Int64).alias(\"len_response_b\"),\n",
    "    )\n",
    "    .with_columns( # 最初のレスポンスのみを取得する\n",
    "        pl.col(\"prompt\").map_elements(lambda x: x[0], return_dtype=pl.String).alias(\"first_prompt\"),\n",
    "        pl.col(\"response_a\").map_elements(lambda x: x[0], return_dtype=pl.String).alias(\"first_response_a\"),\n",
    "        pl.col(\"response_b\").map_elements(lambda x: x[0], return_dtype=pl.String).alias(\"first_response_b\"),\n",
    "    )\n",
    "    .with_columns( # 最後のレスポンスのみを取得する\n",
    "        pl.col(\"prompt\").map_elements(lambda x: x[-1], return_dtype=pl.String).alias(\"last_prompt\"),\n",
    "        pl.col(\"response_a\").map_elements(lambda x: x[-1], return_dtype=pl.String).alias(\"last_response_a\"),\n",
    "        pl.col(\"response_b\").map_elements(lambda x: x[-1], return_dtype=pl.String).alias(\"last_response_b\"),\n",
    "    )\n",
    "    .with_columns( # 最後のレスポンスがNoneの場合を空文字にする、約60件程度\n",
    "        pl.col(\"last_response_a\").fill_null(\"\"),\n",
    "        pl.col(\"last_response_b\").fill_null(\"\"),\n",
    "    )\n",
    "    .with_columns( # labelを付与する\n",
    "        pl.when(pl.col(\"winner_model_a\") == 1)\n",
    "        .then(0)\n",
    "        .when(pl.col(\"winner_model_b\") == 1)\n",
    "        .then(1)\n",
    "        .when(pl.col(\"winner_tie\") == 1)\n",
    "        .then(2)\n",
    "        .alias(\"label\"),\n",
    "    )\n",
    "    .select( # 元のprompt, responseを削除する\n",
    "        pl.exclude([\"prompt\", \"response_a\", \"response_b\"])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_polars(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'len_prompt', 'len_response_a', 'len_response_b', 'first_prompt', 'first_response_a', 'first_response_b', 'last_prompt', 'last_response_a', 'last_response_b', 'label'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chatgpt.com/share/f7a30189-2ca6-4870-96e6-c06120bf4ca7\n",
    "\n",
    "# class CustomDebertaModel(nn.Module):\n",
    "#     def __init__(self, model_name):\n",
    "#         super(CustomDebertaModel, self).__init__()\n",
    "#         self.deberta = DebertaModel.from_pretrained(model_name)\n",
    "#         self.classification_head = nn.Sequential(\n",
    "#             nn.Linear(self.deberta.config.hidden_size * 2, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 1)  # Assuming binary classification\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "#         outputs_a = self.deberta(input_ids=input_ids_a, attention_mask=attention_mask_a)\n",
    "#         outputs_b = self.deberta(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
    "        \n",
    "#         cls_a = outputs_a.last_hidden_state[:, 0, :]  # CLS token\n",
    "#         cls_b = outputs_b.last_hidden_state[:, 0, :]  # CLS token\n",
    "        \n",
    "#         combined = torch.cat((cls_a, cls_b), dim=1)\n",
    "#         logits = self.classification_head(combined)\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # https://github.com/sinchir0/automated_essay_scoring/blob/main/automated_essay_scoring/exp/exp030.ipynb\n",
    "\n",
    "# # https://dev.classmethod.jp/articles/huggingface-usage-custom-model/\n",
    "# # https://github.com/huggingface/transformers/blob/94b3f544a1f5e04b78d87a2ae32a7ac252e22e31/src/transformers/models/deberta_v2/modeling_deberta_v2.py#L1313\n",
    "# class CustomDebertaSequenceClassification(DebertaV2PreTrainedModel):\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__(config)\n",
    "\n",
    "#         num_labels = getattr(config, \"num_labels\", 2)\n",
    "#         self.num_labels = num_labels\n",
    "\n",
    "#         self.deberta = DebertaV2Model(config)\n",
    "#         self.pooler = ContextPooler(config)\n",
    "#         output_dim = self.pooler.output_dim\n",
    "\n",
    "#         self.classifier = nn.Linear(output_dim, num_labels)\n",
    "#         drop_out = getattr(config, \"cls_dropout\", None)\n",
    "#         drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n",
    "#         self.dropout = StableDropout(drop_out)\n",
    "\n",
    "#         # Initialize weights and apply final processing\n",
    "#         self.post_init()\n",
    "\n",
    "#     def get_input_embeddings(self):\n",
    "#         return self.deberta.get_input_embeddings()\n",
    "\n",
    "#     def set_input_embeddings(self, new_embeddings):\n",
    "#         self.deberta.set_input_embeddings(new_embeddings)\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         input_ids: Optional[torch.Tensor] = None,\n",
    "#         attention_mask: Optional[torch.Tensor] = None,\n",
    "#         token_type_ids: Optional[torch.Tensor] = None,\n",
    "#         # position_ids: Optional[torch.Tensor] = None,\n",
    "#         inputs_embeds: Optional[torch.Tensor] = None,\n",
    "#         labels: Optional[torch.Tensor] = None,\n",
    "#         # output_attentions: Optional[bool] = None,\n",
    "#         # output_hidden_states: Optional[bool] = None,\n",
    "#         return_dict: Optional[bool] = None,\n",
    "#     ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "#         return_dict = (\n",
    "#             return_dict if return_dict is not None else self.config.use_return_dict\n",
    "#         )\n",
    "\n",
    "#         outputs = self.deberta(\n",
    "#             input_ids,\n",
    "#             token_type_ids=token_type_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             # position_ids=position_ids,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "#             # output_attentions=output_attentions,\n",
    "#             # output_hidden_states=output_hidden_states,\n",
    "#             return_dict=return_dict,\n",
    "#         )\n",
    "\n",
    "#         encoder_layer = outputs[0]\n",
    "#         pooled_output = self.pooler(encoder_layer)\n",
    "#         pooled_output = self.dropout(pooled_output)\n",
    "#         logits = self.classifier(pooled_output)\n",
    "\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             loss_fn = nn.MSELoss()\n",
    "#             logits = logits.view(-1).to(labels.dtype)\n",
    "#             loss = loss_fn(logits, labels.view(-1))\n",
    "#         # if labels is not None:\n",
    "#         #     if self.config.problem_type is None:\n",
    "#         #         if self.num_labels == 1:\n",
    "#         #             # regression task\n",
    "#         #             loss_fn = nn.MSELoss()\n",
    "#         #             logits = logits.view(-1).to(labels.dtype)\n",
    "#         #             loss = loss_fn(logits, labels.view(-1))\n",
    "#         #         elif labels.dim() == 1 or labels.size(-1) == 1:\n",
    "#         #             label_index = (labels >= 0).nonzero()\n",
    "#         #             labels = labels.long()\n",
    "#         #             if label_index.size(0) > 0:\n",
    "#         #                 labeled_logits = torch.gather(\n",
    "#         #                     logits,\n",
    "#         #                     0,\n",
    "#         #                     label_index.expand(label_index.size(0), logits.size(1)),\n",
    "#         #                 )\n",
    "#         #                 labels = torch.gather(labels, 0, label_index.view(-1))\n",
    "#         #                 loss_fct = CrossEntropyLoss()\n",
    "#         #                 loss = loss_fct(\n",
    "#         #                     labeled_logits.view(-1, self.num_labels).float(),\n",
    "#         #                     labels.view(-1),\n",
    "#         #                 )\n",
    "#         #             else:\n",
    "#         #                 loss = torch.tensor(0).to(logits)\n",
    "#         #         else:\n",
    "#         #             log_softmax = nn.LogSoftmax(-1)\n",
    "#         #             loss = -((log_softmax(logits) * labels).sum(-1)).mean()\n",
    "#         #     elif self.config.problem_type == \"regression\":\n",
    "#         #         loss_fct = MSELoss()\n",
    "#         #         if self.num_labels == 1:\n",
    "#         #             loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "#         #         else:\n",
    "#         #             loss = loss_fct(logits, labels)\n",
    "#         #     elif self.config.problem_type == \"single_label_classification\":\n",
    "#         #         loss_fct = CrossEntropyLoss()\n",
    "#         #         loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "#         #     elif self.config.problem_type == \"multi_label_classification\":\n",
    "#         #         loss_fct = BCEWithLogitsLoss()\n",
    "#         #         loss = loss_fct(logits, labels)\n",
    "#         # if not return_dict:\n",
    "#         #     output = (logits,) + outputs[1:]\n",
    "#         #     return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "#         return SequenceClassifierOutput(\n",
    "#             loss=loss,\n",
    "#             logits=logits,\n",
    "#             # hidden_states=outputs.hidden_states,\n",
    "#             # attentions=outputs.attentions,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/sinchir0/automated_essay_scoring/blob/main/automated_essay_scoring/exp/exp030.ipynb\n",
    "\n",
    "# https://dev.classmethod.jp/articles/huggingface-usage-custom-model/\n",
    "# https://github.com/huggingface/transformers/blob/94b3f544a1f5e04b78d87a2ae32a7ac252e22e31/src/transformers/models/deberta_v2/modeling_deberta_v2.py#L1313\n",
    "class CustomDebertaSequenceClassification(DebertaV2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        num_labels = getattr(config, \"num_labels\", 2)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.deberta = DebertaV2Model(config)\n",
    "        self.pooler = ContextPooler(config)\n",
    "        output_dim = self.pooler.output_dim\n",
    "\n",
    "        self.classifier = nn.Linear(output_dim, num_labels)\n",
    "        drop_out = getattr(config, \"cls_dropout\", None)\n",
    "        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n",
    "        self.dropout = StableDropout(drop_out)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.deberta.get_input_embeddings()\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.deberta.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids_a: Optional[torch.Tensor] = None,\n",
    "        input_ids_b: Optional[torch.Tensor] = None,\n",
    "        attention_mask_a: Optional[torch.Tensor] = None,\n",
    "        attention_mask_b: Optional[torch.Tensor] = None,\n",
    "        token_type_ids_a: Optional[torch.Tensor] = None,\n",
    "        token_type_ids_b: Optional[torch.Tensor] = None,\n",
    "        # position_ids: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds_a: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds_b: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        # output_attentions: Optional[bool] = None,\n",
    "        # output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs_a = self.deberta(\n",
    "            input_ids_a,\n",
    "            token_type_ids=token_type_ids_a,\n",
    "            attention_mask=attention_mask_a,\n",
    "            # position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds_a,\n",
    "            # output_attentions=output_attentions,\n",
    "            # output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        outputs_b = self.deberta(\n",
    "            input_ids_b,\n",
    "            token_type_ids=token_type_ids_b,\n",
    "            attention_mask=attention_mask_b,\n",
    "            # position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds_b,\n",
    "            # output_attentions=output_attentions,\n",
    "            # output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        encoder_layer_a = outputs_a[0]\n",
    "        encoder_layer_b = outputs_b[0]\n",
    "        # TODO: vscodeのdebugを利用して、期待している動作をするかを確認する\n",
    "        # TODO: ここから先を修正する\n",
    "        pooled_output = self.pooler(encoder_layer)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = loss_fn(logits, labels.view(-1))\n",
    "        # if labels is not None:\n",
    "        #     if self.config.problem_type is None:\n",
    "        #         if self.num_labels == 1:\n",
    "        #             # regression task\n",
    "        #             loss_fn = nn.MSELoss()\n",
    "        #             logits = logits.view(-1).to(labels.dtype)\n",
    "        #             loss = loss_fn(logits, labels.view(-1))\n",
    "        #         elif labels.dim() == 1 or labels.size(-1) == 1:\n",
    "        #             label_index = (labels >= 0).nonzero()\n",
    "        #             labels = labels.long()\n",
    "        #             if label_index.size(0) > 0:\n",
    "        #                 labeled_logits = torch.gather(\n",
    "        #                     logits,\n",
    "        #                     0,\n",
    "        #                     label_index.expand(label_index.size(0), logits.size(1)),\n",
    "        #                 )\n",
    "        #                 labels = torch.gather(labels, 0, label_index.view(-1))\n",
    "        #                 loss_fct = CrossEntropyLoss()\n",
    "        #                 loss = loss_fct(\n",
    "        #                     labeled_logits.view(-1, self.num_labels).float(),\n",
    "        #                     labels.view(-1),\n",
    "        #                 )\n",
    "        #             else:\n",
    "        #                 loss = torch.tensor(0).to(logits)\n",
    "        #         else:\n",
    "        #             log_softmax = nn.LogSoftmax(-1)\n",
    "        #             loss = -((log_softmax(logits) * labels).sum(-1)).mean()\n",
    "        #     elif self.config.problem_type == \"regression\":\n",
    "        #         loss_fct = MSELoss()\n",
    "        #         if self.num_labels == 1:\n",
    "        #             loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "        #         else:\n",
    "        #             loss = loss_fct(logits, labels)\n",
    "        #     elif self.config.problem_type == \"single_label_classification\":\n",
    "        #         loss_fct = CrossEntropyLoss()\n",
    "        #         loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        #     elif self.config.problem_type == \"multi_label_classification\":\n",
    "        #         loss_fct = BCEWithLogitsLoss()\n",
    "        #         loss = loss_fct(logits, labels)\n",
    "        # if not return_dict:\n",
    "        #     output = (logits,) + outputs[1:]\n",
    "        #     return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            # hidden_states=outputs.hidden_states,\n",
    "            # attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type deberta-v2 to instantiate a model of type deberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of DebertaModel were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['deberta.encoder.layer.0.attention.self.in_proj.weight', 'deberta.encoder.layer.0.attention.self.pos_proj.weight', 'deberta.encoder.layer.0.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.0.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.0.attention.self.q_bias', 'deberta.encoder.layer.0.attention.self.v_bias', 'deberta.encoder.layer.1.attention.self.in_proj.weight', 'deberta.encoder.layer.1.attention.self.pos_proj.weight', 'deberta.encoder.layer.1.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.1.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.1.attention.self.q_bias', 'deberta.encoder.layer.1.attention.self.v_bias', 'deberta.encoder.layer.10.attention.self.in_proj.weight', 'deberta.encoder.layer.10.attention.self.pos_proj.weight', 'deberta.encoder.layer.10.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.10.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.10.attention.self.q_bias', 'deberta.encoder.layer.10.attention.self.v_bias', 'deberta.encoder.layer.11.attention.self.in_proj.weight', 'deberta.encoder.layer.11.attention.self.pos_proj.weight', 'deberta.encoder.layer.11.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.11.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.11.attention.self.q_bias', 'deberta.encoder.layer.11.attention.self.v_bias', 'deberta.encoder.layer.2.attention.self.in_proj.weight', 'deberta.encoder.layer.2.attention.self.pos_proj.weight', 'deberta.encoder.layer.2.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.2.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.2.attention.self.q_bias', 'deberta.encoder.layer.2.attention.self.v_bias', 'deberta.encoder.layer.3.attention.self.in_proj.weight', 'deberta.encoder.layer.3.attention.self.pos_proj.weight', 'deberta.encoder.layer.3.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.3.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.3.attention.self.q_bias', 'deberta.encoder.layer.3.attention.self.v_bias', 'deberta.encoder.layer.4.attention.self.in_proj.weight', 'deberta.encoder.layer.4.attention.self.pos_proj.weight', 'deberta.encoder.layer.4.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.4.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.4.attention.self.q_bias', 'deberta.encoder.layer.4.attention.self.v_bias', 'deberta.encoder.layer.5.attention.self.in_proj.weight', 'deberta.encoder.layer.5.attention.self.pos_proj.weight', 'deberta.encoder.layer.5.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.5.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.5.attention.self.q_bias', 'deberta.encoder.layer.5.attention.self.v_bias', 'deberta.encoder.layer.6.attention.self.in_proj.weight', 'deberta.encoder.layer.6.attention.self.pos_proj.weight', 'deberta.encoder.layer.6.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.6.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.6.attention.self.q_bias', 'deberta.encoder.layer.6.attention.self.v_bias', 'deberta.encoder.layer.7.attention.self.in_proj.weight', 'deberta.encoder.layer.7.attention.self.pos_proj.weight', 'deberta.encoder.layer.7.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.7.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.7.attention.self.q_bias', 'deberta.encoder.layer.7.attention.self.v_bias', 'deberta.encoder.layer.8.attention.self.in_proj.weight', 'deberta.encoder.layer.8.attention.self.pos_proj.weight', 'deberta.encoder.layer.8.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.8.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.8.attention.self.q_bias', 'deberta.encoder.layer.8.attention.self.v_bias', 'deberta.encoder.layer.9.attention.self.in_proj.weight', 'deberta.encoder.layer.9.attention.self.pos_proj.weight', 'deberta.encoder.layer.9.attention.self.pos_q_proj.bias', 'deberta.encoder.layer.9.attention.self.pos_q_proj.weight', 'deberta.encoder.layer.9.attention.self.q_bias', 'deberta.encoder.layer.9.attention.self.v_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaModel were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized because the shapes did not match:\n",
      "- deberta.encoder.rel_embeddings.weight: found shape torch.Size([512, 384]) in the checkpoint and torch.Size([1024, 384]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ConcatDebertaModel' object has no attribute 'resize_token_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# model = AutoModelForSequenceClassification.from_pretrained(\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     MODEL_NAME,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     num_labels=NUM_LABELS\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m ConcatDebertaModel(model_name\u001b[38;5;241m=\u001b[39mMODEL_NAME)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_token_embeddings\u001b[49m(\u001b[38;5;28mlen\u001b[39m(tokenizer), pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConcatDebertaModel' object has no attribute 'resize_token_embeddings'"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME\n",
    ")\n",
    "tokenizer.add_tokens(\n",
    "    [\n",
    "        AddedToken(\"\\n\", normalized=False),\n",
    "        AddedToken(\" \" * 2, normalized=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     num_labels=NUM_LABELS\n",
    "# )\n",
    "\n",
    "model = ConcatDebertaModel(model_name=MODEL_NAME)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids_a': [1, 266, 15175, 2, 0, 0, 0, 0, 0, 0],\n",
       " 'token_type_ids_a': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask_a': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tokenizer(\n",
    "    \"aaa\",\n",
    "    max_length=10,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    ")\n",
    "\n",
    "{key + '_a': value for key, value in tmp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36c2b50728641a597b59f6cfdb91569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e3d25c30e741c0a7527abdf4cb3edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def tokenize(examples, max_token_length: int):\n",
    "#     separator = \" [SEP] \"\n",
    "    \n",
    "#     joined_text = (\n",
    "#         examples[\"last_prompt\"]\n",
    "#         + separator\n",
    "#         + examples[\"last_response_a\"]\n",
    "#         + separator\n",
    "#         + examples[\"last_response_b\"]\n",
    "#     )\n",
    "\n",
    "#     tokenized = tokenizer(\n",
    "#         joined_text,\n",
    "#         max_length=max_token_length,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "\n",
    "    # return tokenizer(\n",
    "    #     joined_text,\n",
    "    #     max_length=max_token_length,\n",
    "    #     truncation=True,\n",
    "    #     padding=\"max_length\",\n",
    "    # )\n",
    "\n",
    "def tokenize(examples, suffix, max_token_length: int):\n",
    "    separator = \" [SEP] \"\n",
    "    \n",
    "    # TODO: ２つ以上の応答も追加する\n",
    "    joined_text = (\n",
    "        examples[\"last_prompt\"]\n",
    "        + separator\n",
    "        + examples[f\"last_response_{suffix}\"]\n",
    "    )\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        joined_text,\n",
    "        max_length=max_token_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    return {key + f\"_{suffix}\": value for key, value in tokenized.items()}\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "        tokenize,\n",
    "        batched=False,\n",
    "        fn_kwargs={\n",
    "            \"suffix\": \"a\",\n",
    "            \"max_token_length\": TRAINING_MAX_LENGTH\n",
    "        },\n",
    "        num_proc=NUM_PROC,\n",
    "    ).map(\n",
    "        tokenize,\n",
    "        batched=False,\n",
    "        fn_kwargs={\n",
    "            \"suffix\": \"b\",\n",
    "            \"max_token_length\": TRAINING_MAX_LENGTH\n",
    "        },\n",
    "        num_proc=NUM_PROC,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie', 'len_prompt', 'len_response_a', 'len_response_b', 'first_prompt', 'first_response_a', 'first_response_b', 'last_prompt', 'last_response_a', 'last_response_b', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'input_ids_a', 'token_type_ids_a', 'attention_mask_a', 'input_ids_b', 'token_type_ids_b', 'attention_mask_b'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6caa9a93aa42e2b8d4062e6a4744ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_train_valid(ds):\n",
    "    return DatasetDict({\"train\": ds[\"train\"], \"valid\": ds[\"test\"]})\n",
    "\n",
    "train_dataset = train_dataset.cast_column('label', ClassLabel(num_classes=NUM_LABELS))\n",
    "\n",
    "train_valid_dataset = to_train_valid(\n",
    "    (\n",
    "        train_dataset\n",
    "        .train_test_split(\n",
    "            test_size=VALID_DATA_SIZE,\n",
    "            seed=SEED,\n",
    "            stratify_by_column=\"label\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds_prob = softmax(predictions, axis=-1)\n",
    "    return {\"log_loss\": log_loss(labels, preds_prob)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケジューラの設定\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_NUM,\n",
    "    eval_accumulation_steps=GRAD_ACC_NUM,\n",
    "    per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=0.1,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=2,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-08 22:39:31,066] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:25, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.103464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>1.098382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>1.097730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    # モデルの学習\n",
    "    trainer.train()\n",
    "    # ログの保存に利用したストレージを削除\n",
    "    os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "    # モデルの保存\n",
    "    trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "else:\n",
    "    # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        TRAINED_MODEL_PATH,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        \".\",\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6376bb8b434e4d93b552f7c77f6357e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a098e183913c4d278a59af8beacaf245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326f474329f8426da276555f4dcd7735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9197e513421349afaeff989276a3f027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAININGをINFERRENCEでMAX_TOKENを変えるために、validを作り直す\n",
    "valid_dataset = train_dataset.filter(\n",
    "    lambda example: example[\"id\"]\n",
    "    in train_valid_dataset[\"valid\"][\"id\"],\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "\n",
    "def add_valid_pred(example, idx, valid_pred):\n",
    "    example[\"valid_pred\"] = valid_pred[idx]\n",
    "    return example\n",
    "\n",
    "\n",
    "valid_pred = softmax(\n",
    "    trainer.predict(valid_dataset).predictions, axis=-1\n",
    ")\n",
    "\n",
    "np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    add_valid_pred,\n",
    "    with_indices=True,\n",
    "    fn_kwargs={\"valid_pred\": valid_pred}\n",
    ")\n",
    "\n",
    "valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 1.0959604981750728\n"
     ]
    }
   ],
   "source": [
    "cv_score = log_loss(valid_dataset[\"label\"], valid_pred)\n",
    "print(f\"CV Score: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 57.9M  100 57.9M    0     0  6054k      0  0:00:09  0:00:09 --:--:-- 6073k00:09  0:00:05  0:00:04 6186k\n",
      "You can now run: /usr/local/bin/aws --version\n",
      "upload: ../../trained_models/e005-use-first-end/special_tokens_map.json to s3://lmsys/trained_model/e005-use-first-end/special_tokens_map.json\n",
      "upload: ../../trained_models/e005-use-first-end/cv_score.txt to s3://lmsys/trained_model/e005-use-first-end/cv_score.txt\n",
      "upload: ../../trained_models/e005-use-first-end/tokenizer_config.json to s3://lmsys/trained_model/e005-use-first-end/tokenizer_config.json\n",
      "upload: ../../trained_models/e005-use-first-end/added_tokens.json to s3://lmsys/trained_model/e005-use-first-end/added_tokens.json\n",
      "upload: ../../trained_models/e005-use-first-end/config.json to s3://lmsys/trained_model/e005-use-first-end/config.json\n",
      "upload: ../../trained_models/e005-use-first-end/training_args.bin to s3://lmsys/trained_model/e005-use-first-end/training_args.bin\n",
      "upload: ../../trained_models/e005-use-first-end/valid_dataset/dataset_info.json to s3://lmsys/trained_model/e005-use-first-end/valid_dataset/dataset_info.json\n",
      "upload: ../../trained_models/e005-use-first-end/valid_dataset/state.json to s3://lmsys/trained_model/e005-use-first-end/valid_dataset/state.json\n",
      "upload: ../../trained_models/e005-use-first-end/valid_prediction.npy to s3://lmsys/trained_model/e005-use-first-end/valid_prediction.npy\n",
      "upload: ../../trained_models/e005-use-first-end/valid_dataset/data-00000-of-00001.arrow to s3://lmsys/trained_model/e005-use-first-end/valid_dataset/data-00000-of-00001.arrow\n",
      "upload: ../../trained_models/e005-use-first-end/spm.model to s3://lmsys/trained_model/e005-use-first-end/spm.model\n",
      "upload: ../../trained_models/e005-use-first-end/tokenizer.json to s3://lmsys/trained_model/e005-use-first-end/tokenizer.json\n",
      "upload: ../../trained_models/e005-use-first-end/model.safetensors to s3://lmsys/trained_model/e005-use-first-end/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "# S3へのアップロード\n",
    "if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://{COMPETITION_NAME}/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e005-regression /notebooks/automated_essay_scoring/trained_models/e005-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Datasetへのupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"mkdir -p ~/.kaggle/\")\n",
    "os.system(f\"cp /notebooks/{COMPETITION_NAME}/kaggle.json ~/.kaggle/\")\n",
    "os.system(\"chmod 600 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not DEBUG and UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ローカルからのデータの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (UPLOAD_DATA_TO_S3 or UPLOAD_DATA_TO_KAGGLE):\n",
    "    # ローカルからは削除\n",
    "    os.system(f\"rm -rf {MODEL_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish Notebook!\n"
     ]
    }
   ],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
